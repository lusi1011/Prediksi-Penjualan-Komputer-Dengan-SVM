# -*- coding: utf-8 -*-
"""streamlit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1shO92uUQrrLOIZ5jRJSjmyTY4Ah8rROx
"""

# -*- coding: utf-8 -*-
"""
Streamlit SVC Classification Analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score, 
    confusion_matrix
)

# Konfigurasi Halaman
st.set_page_config(layout="wide", page_title="SVC Classification Analysis")
st.title("Analisis Klasifikasi SVM (SVC)")
st.caption("Memprediksi Sub-Kategori (Y) berdasarkan Sales, Profit, dan Quantity (X).")

# --- 1. Fungsi Pembantu dan Pemrosesan Data ---

@st.cache_data
def load_and_process_data():
    """Memuat, memfilter, dan mempersiapkan data untuk KLASIFIKASI."""
    try:
        df = pd.read_csv('SuperStore_Sales_Dataset.csv')
        df = df.rename(columns={'Row ID+O6G3A1:R6': 'Row ID'})
    except FileNotFoundError:
        st.error("File 'SuperStore_Sales_Dataset.csv' tidak ditemukan. Analisis dibatalkan.")
        return None, None, None, None
    except Exception as e:
        st.error(f"Error saat membaca CSV: {e}")
        return None, None, None, None
        
    # Filter data (Technology, non-Phones)
    df_tech = df[df['Category'] == 'Technology']
    df_com = df_tech[df_tech['Sub-Category'] != 'Phones']
    
    # --- PERUBAHAN KUNCI: TARGET ADALAH SUB-KATEGORI ---
    # Fitur adalah metrik numerik.
    features_cols = ['Sales', 'Profit', 'Quantity']
    target_col = 'Product Name'
    
    if target_col not in df_com.columns:
        st.error("Kolom 'Product Name' tidak ditemukan.")
        return None, None, None, None
        
    df_relevant = df_com[features_cols + [target_col]].dropna().copy()

    # Filter data ekstrem (filter ini sekarang berlaku untuk TOTAL per produk)
    df_clean = df_relevant[
        (df_relevant['Sales'] < 3000) & (df_relevant['Sales'] > 0) &
        (df_relevant['Profit'] > -500) & (df_relevant['Profit'] < 800)
    ]
    
    if len(df_clean) < 50: # Butuh lebih banyak data untuk klasifikasi
        st.warning(f"Data tersisa ({len(df_clean)}) terlalu sedikit. Coba longgarkan filter.")
        return None, None, None, None
        
    # Ambil data Fitur (X) dan Target (Y)
    X = df_clean[features_cols]
    Y_raw = df_clean[target_col]
    
    # --- Encode Target (Y) ---
    # Mengubah teks ('Accessories', 'Machines') menjadi angka (0, 1)
    encoder = LabelEncoder()
    Y = encoder.fit_transform(Y_raw)
    class_names = encoder.classes_
    
    # Periksa apakah kita punya cukup kelas
    if len(class_names) < 2:
        st.error("Data yang difilter hanya menghasilkan satu kelas. Klasifikasi tidak mungkin dilakukan.")
        return None, None, None, None
        
    # Sampling yang Aman
    n_samples = 500
    if len(df_clean) < n_samples:
        n_samples = len(df_clean)
        
    df_sample = df_clean.sample(n=n_samples, random_state=42)
    X_sample = df_sample[features_cols]
    Y_sample = encoder.transform(df_sample[target_col])
    
    return X_sample, Y_sample, class_names, df_com


@st.cache_data
def run_feature_selection(X, Y, features_cols):
    """Menjalankan SelectKBest untuk menemukan fitur terbaik untuk KLASIFIKASI."""
    if X is None or len(X) < 10:
        return pd.DataFrame()

    # Scaling diperlukan agar F-scores dapat dibandingkan
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # --- PERUBAHAN: Gunakan f_classif untuk klasifikasi ---
    selector = SelectKBest(f_classif, k='all')
    selector.fit(X_scaled, Y)
    
    scores_df = pd.DataFrame({
        'Fitur': features_cols,
        'F-Score': selector.scores_
    }).sort_values(by='F-Score', ascending=False)
    
    return scores_df

@st.cache_data(show_spinner="Menjalankan Klasifikasi SVC untuk semua kernel...")
def run_all_svc_analysis(X, Y, class_names):
    """Menjalankan SVC untuk semua kernel dan menghitung metrik."""
    
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    kernels = ['linear', 'poly', 'rbf', 'sigmoid']
    model_results = []
    confusion_matrices = {}
    
    for kernel in kernels:
        # Konfigurasi SVC standar
        svc = SVC(kernel=kernel, C=1.0, gamma='scale', random_state=42)
        
        # Fit model
        svc.fit(X_train_scaled, Y_train_scaled)
        
        # Prediksi
        Y_pred = svc.predict(X_test_scaled)
        
        # Hitung Metrik
        # 'weighted' diperlukan untuk multi-kelas yang tidak seimbang
        accuracy = accuracy_score(Y_test, Y_pred)
        precision = precision_score(Y_test, Y_pred, average='weighted', zero_division=0)
        recall = recall_score(Y_test, Y_pred, average='weighted', zero_division=0)
        f1 = f1_score(Y_test, Y_pred, average='weighted', zero_division=0)
        
        # Hitung Confusion Matrix
        cm = confusion_matrix(Y_test, Y_pred, labels=np.arange(len(class_names)))
        
        # Hitung Total TP, TN, FP, FN (secara 'micro')
        # Total Benar adalah jumlah diagonal
        total_benar = np.diag(cm).sum()
        # Total Salah adalah semua selain diagonal
        total_salah = cm.sum() - total_benar
        
        model_results.append({
            'Kernel': kernel,
            'Akurasi': accuracy,
            'Presisi (Weighted)': precision,
            'Recall (Weighted)': recall,
            'F1-Score (Weighted)': f1,
            'Total Benar (TP)': total_benar,
            'Total Salah (FP/FN)': total_salah
        })
        
        confusion_matrices[kernel] = cm

    df_metrics = pd.DataFrame(model_results).sort_values(by='F1-Score (Weighted)', ascending=False)
    
    return df_metrics, confusion_matrices

def create_confusion_matrix_chart(cm, class_names):
    """Membuat plot heatmap Altair untuk Confusion Matrix."""
    
    # Ubah matrix menjadi DataFrame yang rapi
    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)
    df_cm = df_cm.stack().reset_index()
    df_cm.columns = ['Aktual', 'Prediksi', 'Jumlah']

    # Buat chart dasar
    base = alt.Chart(df_cm).encode(
        x=alt.X('Prediksi:O', axis=alt.Axis(title="Prediksi", labelAngle=0)),
        y=alt.Y('Aktual:O', axis=alt.Axis(title="Aktual")),
        tooltip=['Aktual', 'Prediksi', 'Jumlah']
    ).properties(
        title='Confusion Matrix',
        width=alt.Step(80), # Buat kotak lebih besar
        height=alt.Step(80)
    )

    # Buat heatmap
    heatmap = base.mark_rect().encode(
        color=alt.Color('Jumlah:Q', 
                        scale=alt.Scale(range='heatmap'),
                        legend=alt.Legend(title="Jumlah"))
    )

    # Tambahkan teks (angka) di atas heatmap
    text = base.mark_text(baseline='middle').encode(
        text=alt.Text('Jumlah:Q'),
        color=alt.value('black') # Ganti warna teks jika perlu
    )

    chart = heatmap + text
    return chart

# --- 2. Main Streamlit Execution ---

X_data, Y_data, class_names, df_raw_filtered = load_and_process_data()

# Tampilkan Data Mentah
if df_raw_filtered is not None:
    with st.expander("Lihat Data Mentah (Kategori: Technology, Bukan Phones)"):
        st.write(df_raw_filtered)

# Hanya jalankan jika data berhasil di-load dan diproses
if X_data is not None and Y_data is not None and class_names is not None:
    
    features_cols = ['Sales', 'Profit', 'Quantity']

    st.header("1. Target Klasifikasi (Y)")
    st.markdown(f"Tujuan kita adalah memprediksi salah satu dari **{len(class_names)} kelas** berikut:")
    st.json(list(class_names))
    st.markdown("---")

    # --- Bagian 2: Analisis Seleksi Fitur ---
    st.header(f"2. Analisis Fitur (X)")
    st.markdown(f"Fitur mana yang memiliki hubungan statistik terkuat dengan **Sub-Kategori**?")
    
    feature_scores_df = run_feature_selection(X_data, Y_data, features_cols)
    
    if not feature_scores_df.empty:
        st.dataframe(feature_scores_df, use_container_width=True)
        st.caption("Metode: `SelectKBest` dengan `f_classif` (ANOVA F-test). F-Score yang lebih tinggi menunjukkan fitur yang lebih baik untuk klasifikasi.")
    else:
        st.warning("Gagal menjalankan analisis fitur.")
    
    st.markdown("---")

    # --- Bagian 3: Menampilkan Metrik Evaluasi ---
    st.header(f"3. Perbandingan Metrik Kernel SVC")
    
    df_metrics, cm_dict = run_all_svc_analysis(X_data, Y_data, class_names)
    
    if not df_metrics.empty:
        # Format df untuk tampilan
        df_display = df_metrics.copy()
        df_display['Akurasi'] = df_display['Akurasi'].map('{:.2%}'.format)
        df_display['Presisi (Weighted)'] = df_display['Presisi (Weighted)'].map('{:.2%}'.format)
        df_display['Recall (Weighted)'] = df_display['Recall (Weighted)'].map('{:.2%}'.format)
        df_display['F1-Score (Weighted)'] = df_display['F1-Score (Weighted)'].map('{:.2%}'.format)
        
        st.dataframe(df_display, use_container_width=True)
        
        st.subheader("Penjelasan Metrik:")
        st.markdown(f"""
        - **Akurasi**: Persentase total tebakan yang benar.
        - **Presisi (Weighted)**: Seberapa akurat tebakan positif (misal: 'Copiers')? Dihitung rata-rata tertimbang di semua kelas.
        - **Recall (Weighted)**: Berapa banyak dari kelas aktual (misal: semua 'Copiers') yang berhasil ditemukan?
        - **F1-Score (Weighted)**: Keseimbangan antara Presisi dan Recall. Ini seringkali metrik terbaik untuk perbandingan.
        - **Total Benar (TP)**: Jumlah total data (dari test set) yang diklasifikasikan dengan benar.
        - **Total Salah (FP/FN)**: Jumlah total data yang salah diklasifikasikan.
        """)
    else:
        st.warning("Gagal menghitung metrik model.")

    st.markdown("---")
    
    # --- Bagian 4: Visualisasi Confusion Matrix ---
    st.header("4. Visualisasi Confusion Matrix")
    
    if cm_dict:
        # Tentukan kernel terbaik dari tabel metrik
        best_kernel = df_metrics.iloc[0]['Kernel']
        
        st.info(f"Berdasarkan F1-Score, kernel terbaik adalah **{best_kernel}**.")
        
        # Buat tab untuk setiap kernel
        tab_list = [f"Kernel: {k.capitalize()}" for k in df_metrics['Kernel']]
        tabs = st.tabs(tab_list)
        
        for i, kernel_name in enumerate(df_metrics['Kernel']):
            with tabs[i]:
                st.subheader(f"Confusion Matrix untuk Kernel: {kernel_name.capitalize()}")
                
                cm_chart = create_confusion_matrix_chart(cm_dict[kernel_name], class_names)
                st.altair_chart(cm_chart, use_container_width=True)
                
                # Penjelasan CM
                st.markdown(f"""
                **Cara Membaca:**
                - **Sumbu Y (Aktual)**: Label yang sebenarnya dari data.
                - **Sumbu X (Prediksi)**: Label yang diprediksi oleh model.
                - **Diagonal (kiri-atas ke kanan-bawah)**: Tebakan yang **Benar** (True Positives). Semakin tinggi angkanya, semakin baik.
                - **Di luar Diagonal**: Tebakan yang **Salah** (False Positives / False Negatives). Semakin rendah angkanya, semakin baik.
                """)
    
    else:
        st.warning("Gagal menghasilkan Confusion Matrices.")

else:
    if df_raw_filtered is not None:
        st.error(f"Data tersisa tidak cukup untuk analisis klasifikasi. Coba sesuaikan filter di `load_and_process_data`.")
