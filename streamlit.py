# -*- coding: utf-8 -*-
"""streamlit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1shO92uUQrrLOIZ5jRJSjmyTY4Ah8rROx
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.metrics import mean_squared_error, r2_score

# -----------------------------
# Fungsi bantu
# -----------------------------
def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-6))) * 100

st.set_page_config(page_title="Prediksi SVR SuperStore", layout="wide")
st.title("üìä Analisis Prediksi Penjualan Produk (SVR)")

# Upload file CSV
uploaded_file = st.file_uploader("üìÇ Unggah file dataset (CSV)", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df.columns = df.columns.str.strip()

    st.subheader("üîç Cuplikan Dataset")
    st.dataframe(df.head())

    # --- Pra-pemrosesan Data ---
    df_filtered = df[
        (df['Category'] == 'Technology') &
        (df['Sub-Category'] != 'Phones')
    ].copy()

    st.write(f"Jumlah data setelah filter: **{len(df_filtered)}** dari total **{len(df)}**")

    if df_filtered.empty:
        st.error("‚ùå Setelah filtering, data kosong. Tidak dapat melanjutkan.")
        st.stop()

    # Agregasi data per produk
    product_stats = df_filtered.groupby('Product Name').agg(
        Total_Quantity=('Quantity', 'sum'),
        Mean_Sales=('Sales', 'mean'),
        Mean_Profit=('Profit', 'mean'),
        Count_Orders=('Order ID', 'nunique')
    ).reset_index()

    product_stats = product_stats.replace([np.inf, -np.inf], np.nan).dropna()

    X_products = product_stats[['Product Name', 'Mean_Sales', 'Mean_Profit', 'Count_Orders']]
    y_products = product_stats['Total_Quantity']
    feature_cols = ['Mean_Sales', 'Mean_Profit', 'Count_Orders']

    # Split data
    X_train_full, X_test_full, y_train, y_test = train_test_split(
        X_products, y_products, test_size=0.2, random_state=42
    )
    X_test = X_test_full[feature_cols]
    X_train = X_train_full[feature_cols]

    # Scaling
    scaler_X = StandardScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    scaler_y = StandardScaler()
    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()

    # Feature Selection
    selector = SelectKBest(score_func=f_regression, k=1)
    # Fit pada data latih
    X_train_selected_all = selector.fit_transform(X_train_scaled, y_train_scaled)
    # Transform pada data tes
    X_test_selected_all = selector.transform(X_test_scaled)
    selected_indices = selector.get_support(indices=True)
    selected_feature_names = [feature_cols[i] for i in selected_indices]
    selected_feature_name_for_plot = selected_feature_names[0]

    st.success("‚úÖ Data berhasil diproses dan siap untuk pelatihan model.")

    # --- Hyperparameter Tuning ---
    with st.spinner("üîÑ Melatih model SVR..."):
        param_grid_rbf = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 'scale']}
        grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid_rbf, cv=5, scoring='r2', n_jobs=-1)
        grid_search_rbf.fit(X_train_selected_all, y_train_scaled)
        best_rbf_svr = grid_search_rbf.best_estimator_
        best_rbf_params = grid_search_rbf.best_params_

        param_grid_poly = {
            'C': [0.1, 1, 10],
            'gamma': [0.1, 1, 'scale'],
            'coef0': [0, 1, 2],
            'degree': [2, 3, 4]
        }
        grid_search_poly = GridSearchCV(SVR(kernel='poly'), param_grid_poly, cv=5, scoring='r2', n_jobs=-1)
        grid_search_poly.fit(X_train_selected_all, y_train_scaled)
        best_poly_svr = grid_search_poly.best_estimator_
        best_poly_params = best_poly_svr.get_params()

        param_grid_sigmoid = {
            'C': [0.1, 1, 10],
            'gamma': [0.1, 1, 'scale'],
            'coef0': [-2, -1, 0, 1, 2]
        }
        grid_search_sigmoid = GridSearchCV(SVR(kernel='sigmoid'), param_grid_sigmoid, cv=5, scoring='r2', n_jobs=-1)
        grid_search_sigmoid.fit(X_train_selected_all, y_train_scaled)
        best_sigmoid_svr = grid_search_sigmoid.best_estimator_
        best_sigmoid_params = best_sigmoid_svr.get_params()

        model_linear = SVR(kernel='linear', C=10, gamma='scale').fit(X_train_selected_all, y_train_scaled)

    model_dict = {
        'Linear': model_linear,
        'Poly Tuned': best_poly_svr,
        'RBF Tuned': best_rbf_svr,
        'Sigmoid Tuned': best_sigmoid_svr
    }

    # --- Evaluasi Model ---
    results = []
    for name, model in model_dict.items():
        y_pred_scaled = model.predict(X_test_selected_all)
        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        mape = mean_absolute_percentage_error(y_test, y_pred)
        results.append({'Model': name, 'R2': r2, 'MSE': mse, 'MAPE': mape})

    results_df = pd.DataFrame(results).sort_values(by='R2', ascending=False)
    st.subheader("üìà Hasil Evaluasi Model")
    st.dataframe(results_df.style.highlight_max(axis=0, subset=['R2'], color='lightgreen').highlight_min(axis=0, subset=['MSE', 'MAPE'], color='lightpink'))

    # --- Visualisasi ---
    st.subheader("üé® Visualisasi Hasil Prediksi")

    # Ambil nilai fitur *original* (sebelum scaling) dari data tes untuk sumbu X
    X_test_original = scaler_X.inverse_transform(X_test_scaled)
    X_test_selected_original_plot = X_test_original[:, selected_indices[0]]

    fig, axes = plt.subplots(1, 4, figsize=(20, 5), sharey=True) # Share Y-axis
    sns.set_style("whitegrid")

    for i, (name, model) in enumerate(model_dict.items()):
        ax = axes[i]

        # --- PERBAIKAN UNTUK GARIS HALUS ---
        
        # 1. Buat range X yang halus di 'original space' (unscaled)
        x_min_orig = X_test_selected_original_plot.min()
        x_max_orig = X_test_selected_original_plot.max()
        # Buat 300 titik data halus antara min dan max
        x_smooth_orig = np.linspace(x_min_orig, x_max_orig, 300)

        # 2. Kita perlu scaling X halus ini seperti data training
        # Ambil mean dan std dari scaler UNTUK FITUR YANG DIPILIH
        selected_feature_index = selected_indices[0]
        mean_feat = scaler_X.mean_[selected_feature_index]
        std_feat = scaler_X.scale_[selected_feature_index]
        
        # 3. Lakukan scaling manual pada data halus
        x_smooth_scaled = (x_smooth_orig - mean_feat) / std_feat
        
        # 4. Reshape agar bisa di-predict oleh model (model mengharapkan input 2D)
        x_smooth_scaled_reshaped = x_smooth_scaled.reshape(-1, 1)

        # 5. Lakukan prediksi pada data halus yang sudah di-scale
        y_smooth_pred_scaled = model.predict(x_smooth_scaled_reshaped)

        # 6. Kembalikan Y (hasil prediksi) ke 'original space'
        y_smooth_pred_orig = scaler_y.inverse_transform(y_smooth_pred_scaled.reshape(-1, 1)).flatten()

        # --- Plotting ---
        
        # 7. Scatter plot untuk data *aktual* (titik-titik abu-abu)
        # Kita gunakan data tes yang asli
        ax.scatter(X_test_selected_original_plot, y_test, color='gray', label='Aktual', alpha=0.5)

        # 8. Plot garis prediksi yang HALUS (garis biru)
        ax.plot(x_smooth_orig, y_smooth_pred_orig, color='blue', linewidth=2, label=f'Prediksi {name}')
        
        # --- Akhir Perbaikan ---

        ax.set_title(name)
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.7)
        
        # Tambahkan label
        ax.set_xlabel(selected_feature_name_for_plot)
        if i == 0: # Hanya set label Y di plot pertama
            ax.set_ylabel('Total Quantity (Prediksi vs Aktual)')


    plt.tight_layout()
    st.pyplot(fig)

    st.success("‚úÖ Semua proses selesai! Model SVR berhasil dijalankan dan divisualisasikan.")
else:
    st.info("üëÜ Unggah file CSV untuk memulai analisis.")
