# -*- coding: utf-8 -*-
"""streamlitsvr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zDg5UMjK1af5nQYwWkTQI_9i7OItWawr
"""

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

st.set_page_config(layout="wide")
st.title("ðŸš€ Analisis Support Vector Regression (SVR) pada Data Penjualan")

# --- 1. Fungsi Pembantu dan Pemrosesan Data ---

# Fungsi kustom untuk menghitung MAPE
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    y_true[y_true == 0] = 1e-6 
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Cache data agar proses ini hanya berjalan sekali
@st.cache_data
def load_and_process_data():
    df = pd.read_csv("SuperStore_Sales_Dataset.csv", sep=",", na_values="#N/A")
    df_clean = df[['Sales', 'Profit', 'Quantity']].dropna().copy()
    
    # Filter data ekstrem (sama seperti sebelumnya)
    df_clean = df_clean[(df_clean['Sales'] < 3000) & 
                        (df_clean['Sales'] > 0) & 
                        (df_clean['Profit'] > -500) & 
                        (df_clean['Profit'] < 800)]
    
    # Mengambil subset untuk efisiensi komputasi SVR
    return df_clean.sample(n=3000, random_state=42)

@st.cache_data
def run_svr_analysis(df_clean):
    X = df_clean['Profit'].values.reshape(-1, 1)
    Y = df_clean['Sales'].values.reshape(-1, 1)

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
    scaler_X = StandardScaler()
    scaler_Y = StandardScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    Y_train_scaled = scaler_Y.fit_transform(Y_train).ravel()

    kernels = ['poly', 'rbf', 'sigmoid']
    model_results = []
    
    # **OPTIMASI 1: Kurangi titik data untuk plot hyperplane**
    # Hanya 50 titik untuk garis hyperplane, bukan 100
    X_range_scaled = np.linspace(X_train_scaled.min(), X_train_scaled.max(), 50).reshape(-1, 1)
    
    # Siapkan DataFrame untuk hasil plot gabungan (data aktual dan prediksi)
    plot_data_list = []

    # Ambil 50 data acak dari test set untuk SCATTER PLOT
    df_test_sample = pd.DataFrame({'Profit': X_test.ravel(), 'Sales': Y_test.ravel()})
    df_test_sample = df_test_sample.sample(n=50, random_state=42).copy() # HANYA 50 TITIK!
    df_test_sample['Type'] = 'Actual'

    for kernel in kernels:
        svr = SVR(kernel=kernel, C=100, gamma='auto') 
        svr.fit(X_train_scaled, Y_train_scaled)
        
        # ... (Evaluasi Metrik tetap sama) ...
        Y_pred_test_scaled = svr.predict(X_test_scaled)
        Y_pred_test = scaler_Y.inverse_transform(Y_pred_test_scaled.reshape(-1, 1))
        mse = mean_squared_error(Y_test, Y_pred_test)
        r2 = r2_score(Y_test, Y_pred_test)
        mape = mean_absolute_percentage_error(Y_test, Y_pred_test)
        model_results.append({'Kernel': kernel, 'MSE': mse, 'R2': r2, 'MAPE': mape})

        # Prediksi untuk plotting hyperplane (GARIS)
        Y_pred_range_scaled = svr.predict(X_range_scaled)
        Y_pred_range = scaler_Y.inverse_transform(Y_pred_range_scaled.reshape(-1, 1))

        # **OPTIMASI 2: Buat DataFrame Prediksi dan Gabungkan dengan Data Sample**
        df_pred = pd.DataFrame({
            'Profit': scaler_X.inverse_transform(X_range_scaled).ravel(),
            'Sales': Y_pred_range.ravel(),
            'Kernel': kernel,
            'Type': 'Prediction'
        })
        
        # Gabungkan data aktual (sample) dan prediksi (garis)
        # Data aktual diulang 4 kali (untuk setiap kernel facet)
        df_actual_temp = df_test_sample.copy()
        df_actual_temp['Kernel'] = kernel
        
        plot_data_list.append(df_actual_temp)
        plot_data_list.append(df_pred)

    df_metrics = pd.DataFrame(model_results)
    df_plot_final = pd.concat(plot_data_list, ignore_index=True)

    return df_metrics, df_plot_final

# --- 2. Main Streamlit Execution ---
df_clean = load_and_process_data()
df_metrics, df_plot_final = run_svr_analysis(df_clean)

# ... (Bagian 3: Menampilkan Metrik Evaluasi tetap sama) ...
st.header("1. Metrik Evaluasi Model")

df_metrics['MSE'] = df_metrics['MSE'].round(2)
df_metrics['R2'] = df_metrics['R2'].round(4)
df_metrics['MAPE'] = df_metrics['MAPE'].round(2).astype(str) + ' %'

st.table(df_metrics.sort_values(by='R2', ascending=False))

# --- 4. Menampilkan Grafik Hyperplane (Altair) ---
st.header("2. Visualisasi Hyperplane Regresi (Altair)")

# **OPTIMASI 3: Satu Chart Saja dengan Kondisi**
base = alt.Chart(df_plot_final).encode(
    x=alt.X('Profit', title='Keuntungan (Profit)'),
    y=alt.Y('Sales', title='Penjualan (Sales)'),
    tooltip=['Profit', 'Sales', 'Kernel']
)

# Scatter plot: Hanya tampilkan titik untuk Type == 'Actual'
scatter = base.transform_filter(
    alt.FieldEqualPredicate(field='Type', equal='Actual')
).mark_point(opacity=0.6, size=20, color='gray')

# Line chart: Hanya tampilkan garis untuk Type == 'Prediction'
line = base.transform_filter(
    alt.FieldEqualPredicate(field='Type', equal='Prediction')
).mark_line(size=3).encode(
    color=alt.Color('Kernel', title='Kernel SVR')
)

# Gabungkan dan Facet
chart = (scatter + line).facet(
    column=alt.Column('Kernel', header=alt.Header(titleOrient="bottom", labelOrient="bottom")),
    columns=2
).properties(
    title="Perbandingan Hyperplane SVR Berdasarkan Kernel (Sales vs. Profit)"
)

st.altair_chart(chart, use_container_width=True)

# ... (Bagian Analisis Visual tetap sama) ...
st.markdown("""
**Analisis Visual:**
* **Kernel Linear** (garis lurus) menunjukkan garis regresi yang paling masuk akal, yang konsisten dengan metrik evaluasi yang menyatakan kernel ini paling baik memprediksi *Sales* di dataset ini.
* **Kernel Non-Linear** (*rbf*, *poly*, *sigmoid*) menghasilkan kurva yang aneh karena data penjualan dan keuntungan seringkali tidak memiliki hubungan non-linear yang kompleks dan terstruktur seperti yang diasumsikan kernel-kernel tersebut.
""")
